
# 경사하강법

- 경사하강법은 [[손실함수]]의 기울기를 따라 내려가면서 파라메터를 업데이트하는 알고리즘으로 이를 통해 손실함수를 최소화하고 최적의 파라미터를 찾는다.

이해하기 쉽게 설명하자면,

```
안개낀 산을 내려가는 방법
- 안개때문에 발 아래만 볼 수 있다. 
- 발 아래에서 가장 가파른 방향으로 한걸음씩 내려간다.
- 이를 반복한다.
```

- 인공지능이 학습하는 방법 중하나로 산에서 가장 낮은 곳을 찾아 가는 것처럼 작동한다.
- `error(오차)`와 `loss(손실)`은 산의 높이를 뜻하고 이를 줄여가는 것(산을 내려가는것)이 목표다.
- 손실함수의 `경사` 를 따라 내려가면서 최적의 모델 파라미터를 찾는것

## 학습률(Learning Rate)

- 학습률은 각 반복에서 파라미터를 얼마자 업데이트할지 결정하는 하이퍼파라미터.
	- 높은 학습률: 빠른 학습이 가능하지만 수렴하지 않거나 발산할 수 있음
	- 낮은 학습률: 안정적이지만 *local minima*에 빠지거나 속도가 매우 느릴 수 있다.

## 안장점

- 말의 안정처럼 생긴 평평한 지점 -> 멈주면 안돼!
- 특징: 한 방향으로 오목하고, 다른 방향으로는 볼록하다
- 경사가 0이라 경사하강법이 멈출 수 있어서 모멘텀같은 기법을 사용해 이 지점을 통과해야 함.

## 국소 최소값 vs 전역 최소값

- Local Minima: 주변에서는 가장 낮지만, 전체에서 봤을 때 가장 낮지 않은 지점
- Global Minima: 전체 영역에서 가장 낮은 지점
